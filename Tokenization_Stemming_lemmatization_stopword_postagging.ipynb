{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tokenization_Stemming_lemmatization_stopword_postagging.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOq05dER6s1tk+xU4EsWPJf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Satyamaadi/python/blob/master/Tokenization_Stemming_lemmatization_stopword_postagging.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3A9uZgwZCw_"
      },
      "source": [
        "##Data cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SgZKjWqGVIyp"
      },
      "source": [
        "corpus_original = \"Need to finalize the demo corpus which will be used for this notebook and it should be done soon !!. It should be done by the ending of this month. But will it? This notebook has been run 4 times !!\"\n",
        "corpus = \"Need to finalize the demo corpus which will be used for this notebook & should be done soon !!. It should be done by the ending of this month. But will it? This notebook has been run 4 times !!\""
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eETB1g_5VRu7"
      },
      "source": [
        "corpus = corpus.lower()"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4OaQ4l6EVZfG"
      },
      "source": [
        "import re"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IwdD9BMmVcap"
      },
      "source": [
        "corpus = re.sub(r'\\d+','',corpus) #removing digits from corpus"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a98x1D6EWvKi",
        "outputId": "fd550543-c2e7-49b1-fe28-6123aa85e34a"
      },
      "source": [
        "print(corpus)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "need to finalize the demo corpus which will be used for this notebook & should be done soon !!. it should be done by the ending of this month. but will it? this notebook has been run  times !!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDNR7l_cWwjP"
      },
      "source": [
        "import string  \n",
        "corpus = corpus.translate(str.maketrans('','',string.punctuation))  #remove punctuations from corpus "
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Z97Az83XEuf",
        "outputId": "7fd48b15-3f9c-4dbd-cc29-85b684049885"
      },
      "source": [
        "print(corpus)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "need to finalize the demo corpus which will be used for this notebook  should be done soon  it should be done by the ending of this month but will it this notebook has been run  times \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fV-5w0oFXGa1"
      },
      "source": [
        "corpus = ' '.join([token for token in corpus.split()]) #emove whitespaces that are trailing"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "ULa4DL8aXc7o",
        "outputId": "0c96b0d0-464c-4253-c7b2-a450f813c2f8"
      },
      "source": [
        "corpus"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'need to finalize the demo corpus which will be used for this notebook should be done soon it should be done by the ending of this month but will it this notebook has been run times'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ghYdDVhZF_E"
      },
      "source": [
        "##Tokenisation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wFEaXGCDXeuI",
        "outputId": "e76ecce4-94e2-406c-f49a-f59c2032d464"
      },
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "stop_words_nltk = set(stopwords.words('english'))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AuLVETfqXs97"
      },
      "source": [
        "tokenized_corpus_nltk = word_tokenize(corpus)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lX6-5xPVYX9G",
        "outputId": "d43cb92d-594f-4523-b9b5-769aa6f2105a"
      },
      "source": [
        "tokenized_corpus_nltk"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['need',\n",
              " 'to',\n",
              " 'finalize',\n",
              " 'the',\n",
              " 'demo',\n",
              " 'corpus',\n",
              " 'which',\n",
              " 'will',\n",
              " 'be',\n",
              " 'used',\n",
              " 'for',\n",
              " 'this',\n",
              " 'notebook',\n",
              " 'should',\n",
              " 'be',\n",
              " 'done',\n",
              " 'soon',\n",
              " 'it',\n",
              " 'should',\n",
              " 'be',\n",
              " 'done',\n",
              " 'by',\n",
              " 'the',\n",
              " 'ending',\n",
              " 'of',\n",
              " 'this',\n",
              " 'month',\n",
              " 'but',\n",
              " 'will',\n",
              " 'it',\n",
              " 'this',\n",
              " 'notebook',\n",
              " 'has',\n",
              " 'been',\n",
              " 'run',\n",
              " 'times']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TUTjUSViYawQ"
      },
      "source": [
        "tokenized_words_without_stopwords = [i for i in tokenized_corpus_nltk if not i in stop_words_nltk]"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_SHNSuc_Yve5",
        "outputId": "4ef4bb20-4821-49a8-d634-e0eb64d48e49"
      },
      "source": [
        "tokenized_words_without_stopwords"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['need',\n",
              " 'finalize',\n",
              " 'demo',\n",
              " 'corpus',\n",
              " 'used',\n",
              " 'notebook',\n",
              " 'done',\n",
              " 'soon',\n",
              " 'done',\n",
              " 'ending',\n",
              " 'month',\n",
              " 'notebook',\n",
              " 'run',\n",
              " 'times']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0YjDqYNZJRI"
      },
      "source": [
        "##Stemming"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6BgaStPYxVU"
      },
      "source": [
        "from nltk.stem import PorterStemmer"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8ZOFEE2ZUck"
      },
      "source": [
        "stemmer = PorterStemmer()"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qavKGYLuZWWQ",
        "outputId": "ef901b0c-dda4-4a7c-9c92-ad45a27dbd0f"
      },
      "source": [
        "print(\"Before stemming:\",corpus)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Before stemming: need to finalize the demo corpus which will be used for this notebook should be done soon it should be done by the ending of this month but will it this notebook has been run times\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v-QxXocIZa6-",
        "outputId": "6e6fa601-9489-417d-f3fe-90ecf829c1b8"
      },
      "source": [
        "for word in tokenized_corpus_nltk:\n",
        "  print(stemmer.stem(word),end=\" \")"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "need to final the demo corpu which will be use for thi notebook should be done soon it should be done by the end of thi month but will it thi notebook ha been run time "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UAD-nKDqZ6eY"
      },
      "source": [
        "##Lemmatization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CUG7UsMoZrCO",
        "outputId": "7d3b0b32-d66f-4821-edac-f71861e5ab64"
      },
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S28fLLvsaIP4"
      },
      "source": [
        "lemmatizer = WordNetLemmatizer()"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mFYsxU55aN9f",
        "outputId": "4a0a0072-238c-4abc-bcb9-3e8e209cd3f5"
      },
      "source": [
        "for word in tokenized_corpus_nltk:\n",
        "  print(lemmatizer.lemmatize(word),end=\" \")"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "need to finalize the demo corpus which will be used for this notebook should be done soon it should be done by the ending of this month but will it this notebook ha been run time "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8W1dNg7sanzW"
      },
      "source": [
        "##Pos tagging"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KCf1Qz15aZfm"
      },
      "source": [
        "import spacy\n",
        "spacy_model = spacy.load('en_core_web_sm')"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zkJZnNH-asvw"
      },
      "source": [
        "doc = spacy_model(corpus_original)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EMV1a0e8a1c7",
        "outputId": "c39d78d7-4160-4086-b5ec-e4c7c516aa7a"
      },
      "source": [
        "for token in doc:\n",
        "  print(token , token.pos_)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Need VERB\n",
            "to PART\n",
            "finalize VERB\n",
            "the DET\n",
            "demo NOUN\n",
            "corpus NOUN\n",
            "which DET\n",
            "will VERB\n",
            "be AUX\n",
            "used VERB\n",
            "for ADP\n",
            "this DET\n",
            "notebook NOUN\n",
            "and CCONJ\n",
            "it PRON\n",
            "should VERB\n",
            "be AUX\n",
            "done VERB\n",
            "soon ADV\n",
            "! PUNCT\n",
            "! PUNCT\n",
            ". PUNCT\n",
            "It PRON\n",
            "should VERB\n",
            "be AUX\n",
            "done VERB\n",
            "by ADP\n",
            "the DET\n",
            "ending NOUN\n",
            "of ADP\n",
            "this DET\n",
            "month NOUN\n",
            ". PUNCT\n",
            "But CCONJ\n",
            "will VERB\n",
            "it PRON\n",
            "? PUNCT\n",
            "This DET\n",
            "notebook NOUN\n",
            "has AUX\n",
            "been AUX\n",
            "run VERB\n",
            "4 NUM\n",
            "times NOUN\n",
            "! PUNCT\n",
            "! PUNCT\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OM-cSP5ja8hQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}